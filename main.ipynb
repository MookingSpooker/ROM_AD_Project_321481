{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction",
   "id": "783fd4f9e9c32d6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Project initialization and setup",
   "id": "d478de8170d09849"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing all of the libraries that will be used. In the project.",
   "id": "36e8af2fe148df25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "ee35db9716a8b132"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Display options (make this clearer)",
   "id": "80227c6281264505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)"
   ],
   "id": "47717ab936a80b8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Explain what this is",
   "id": "49af731a530be5a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DB_PATH = \"viewer_interactions.db\"\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    print(\"Connected successfully!\")\n",
    "except sqlite3.Error as e:\n",
    "    print(\"Connection failed:\", e)"
   ],
   "id": "a6eb6392ad09ef87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Listing all the tables",
   "id": "2a6b81d2d55984a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tables_query = \"\"\"\n",
    "               SELECT name\n",
    "               FROM sqlite_master\n",
    "               WHERE type='table'\n",
    "               ORDER BY name; \\\n",
    "               \"\"\"\n",
    "\n",
    "tables_df = pd.read_sql_query(tables_query, conn)\n",
    "print(\"Tables in the database:\")\n",
    "display(tables_df)"
   ],
   "id": "bf29c3598bd43677"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "table_names = tables_df[\"name\"].tolist()\n",
    "\n",
    "schemas = {}\n",
    "\n",
    "for table in table_names:\n",
    "    pragma_query = f\"PRAGMA table_info({table});\"\n",
    "    schema_df = pd.read_sql_query(pragma_query, conn)\n",
    "    schemas[table] = schema_df\n",
    "    print(f\"\\nSchema for table '{table}':\")\n",
    "    display(schema_df)"
   ],
   "id": "3ef99a4edcf56482"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating a dictionary of type table_name -> DataFrame",
   "id": "48921d43d433f762"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dfs = {\n",
    "#    \"interactions\": DataFrame with columns [user_id, movie_id, rating, timestamp, ...],\n",
    "#    \"movies\":       DataFrame with columns [movie_id, title, genres, year, ...],\n",
    "#    \"users\":        DataFrame with columns [user_id, age, country, ...]\n",
    "# }"
   ],
   "id": "fc579e4a507558a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data frame shape where shape is the number of rows and the second number is the number of columns. We are specifically grabbing the names of the sets of tables",
   "id": "72b0c21d162dcb00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dfs = {}\n",
    "\n",
    "for t in table_names:\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {t};\", conn)\n",
    "    dfs[t] = df\n",
    "    print(f\"\\nLoaded table '{t}' with shape {df.shape}\")"
   ],
   "id": "3942fa015f32535"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example of using the dfs dictionary",
   "id": "4616c48ae2f2c277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def search_by_parameter(table_name, key, value):\n",
    "    df = dfs[table_name]\n",
    "\n",
    "    if value is None:\n",
    "        return df[df[key].isna()]\n",
    "\n",
    "    return df[df[key] == value]"
   ],
   "id": "41b7c69238a87009"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Giacomo thing",
   "id": "ff80451ed6931921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    tables = pd.read_sql(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\",\n",
    "        conn\n",
    "    )['name'].tolist()\n",
    "\n",
    "    print(\"=== DATA DICTIONARY ===\\n\")\n",
    "\n",
    "    for table in tables:\n",
    "        print(f\"Table: {table}\")\n",
    "        print(\"-\" * (7 + len(table)))\n",
    "\n",
    "        # Get actual column info from PRAGMA but filter to nice output\n",
    "        schema = pd.read_sql(f\"PRAGMA table_info('{table}')\", conn)\n",
    "\n",
    "        # Keep only real schema fields you want (remove cid, default, pk if desired)\n",
    "        clean_schema = schema[['name', 'type', ]]\n",
    "\n",
    "        print(clean_schema.to_string(index=False))\n",
    "        print(\"\\n\")"
   ],
   "id": "8b71a2e4542d18c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for name, df in dfs.items():\n",
    "    print(f\"\\n{name} missing values (%):\")\n",
    "    missing_pct = df.isna().mean() * 100\n",
    "    display(missing_pct.to_frame(\"missing_%\"))"
   ],
   "id": "62a9946e839b8df7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Counting all missing values, diagnostics purposes only",
   "id": "888e89f6fa4cbb96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A function to calculate missing std. ratings of films",
   "id": "68178651177d9a30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_film_std(df):\n",
    "    film_stats = (\n",
    "        df.groupby('movie_id')['rating']\n",
    "        .apply(list)\n",
    "        .reset_index(name='ratings')\n",
    "    )\n",
    "\n",
    "    def manual_std(ratings):\n",
    "        ratings = np.array(ratings)\n",
    "        n = len(ratings)\n",
    "        if n <= 1:\n",
    "            return 0.0\n",
    "        mean = ratings.mean()\n",
    "        return np.sqrt(((ratings - mean) ** 2).mean())\n",
    "\n",
    "    film_stats['std_rating'] = film_stats['ratings'].apply(manual_std)\n",
    "\n",
    "    return film_stats[['movie_id', 'std_rating']]\n",
    "\n",
    "# Compute std for all films\n",
    "viewer_ratings = dfs['viewer_ratings']\n",
    "film_std = compute_film_std(viewer_ratings)\n",
    "\n",
    "# Load movies_statistics\n",
    "movies_stats = dfs[\"movie_statistics\"]\n",
    "\n",
    "# Compute the old percentage before merging\n",
    "old_null_pct = dfs[\"movie_statistics\"][\"std_rating\"].isna().mean() * 100\n",
    "\n",
    "# Merge new std values\n",
    "movies_stats = movies_stats.merge(\n",
    "    film_std,\n",
    "    on=\"movie_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_new\")\n",
    ")\n",
    "\n",
    "# Replace old std_rating with the new one\n",
    "movies_stats[\"std_rating\"] = movies_stats[\"std_rating_new\"]\n",
    "movies_stats.drop(columns=[\"std_rating_new\"], inplace=True)\n",
    "\n",
    "# Save updated table\n",
    "dfs[\"movie_statistics\"] = movies_stats\n",
    "\n",
    "# Compute new percentage ---\n",
    "new_null_pct = movies_stats[\"std_rating\"].isna().mean() * 100\n",
    "\n",
    "# absolute improvement (percentage points)\n",
    "improvement_abs = old_null_pct - new_null_pct\n",
    "\n",
    "# relative improvement (how many percent of the original NaNs we removed)\n",
    "improvement_rel = (improvement_abs / old_null_pct) * 100 if old_null_pct > 0 else 0\n",
    "\n",
    "print(f\"Missing values reduced from {old_null_pct:.2f}% to {new_null_pct:.2f}%.\")\n",
    "print(f\"Absolute improvement: {improvement_abs:.2f}%\")\n",
    "print(f\"Relative improvement: {improvement_rel:.2f}% better than before.\")"
   ],
   "id": "27ce33758866289d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Figure out how to drop na values in general\n",
    "movie_stats = dfs['movie_statistics']\n",
    "#print(movie_stats[movie_stats['std_rating'] == pd.isnull(movie_stats['std_rating'])])\n",
    "#movie_stats = movie_stats[movie_stats['std_rating'].notna()]\n",
    "#print(movie_stats)\n",
    "\n",
    "print(f\"Before cleaning: {len(movie_stats)} movies\")\n",
    "movie_stats = movie_stats.dropna(subset=['std_rating'])\n",
    "dfs['movie_statistics'] = movie_stats\n",
    "print(f\"After removing single-rating movies: {len(movie_stats)} movies\")"
   ],
   "id": "9edcbab6747948c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculating the missing total_ratings for movies",
   "id": "775f6f37c13e3928"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movie_stats = dfs[\"movie_statistics\"]\n",
    "viewer_ratings = dfs[\"viewer_ratings\"]\n",
    "\n",
    "# Collecting all the movies with absent total_rating in a dictionary\n",
    "missing_dict = {}\n",
    "\n",
    "missing = search_by_parameter('movie_statistics', 'total_ratings', None)\n",
    "missing_dict = {row.movie_id: 0 for row in missing.itertuples(index=False)}\n",
    "\n",
    "# Iterating through viewer_ratings and manually counting the ratings for each film\n",
    "for row in viewer_ratings.itertuples(index=False):\n",
    "    movie_id = row.movie_id\n",
    "    if movie_id in missing_dict:\n",
    "        missing_dict[movie_id] += 1\n",
    "\n",
    "# Update movie_stats\n",
    "for row in movie_stats.itertuples(index=True):\n",
    "    if row.movie_id in missing_dict:\n",
    "        movie_stats.at[row.Index, \"total_ratings\"] = missing_dict[row.movie_id]\n",
    "\n",
    "dfs[\"movie_statistics\"] = movie_stats"
   ],
   "id": "96e006713aa831d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movie_stats = dfs[\"movie_statistics\"]\n",
    "viewer_ratings = dfs[\"viewer_ratings\"]\n",
    "\n",
    "# Find movies with missing min_rating and max_rating using your function\n",
    "missing_min = search_by_parameter('movie_statistics', 'min_rating', None)\n",
    "missing_max = search_by_parameter('movie_statistics', 'max_rating', None)\n",
    "\n",
    "# Combine them, because some movies may be in both\n",
    "missing_ids = set(missing_min[\"movie_id\"]) | set(missing_max[\"movie_id\"])\n",
    "\n",
    "# Finding relevant movie ratings in viewer_ratings table\n",
    "relevant_ratings = viewer_ratings[viewer_ratings[\"movie_id\"].isin(missing_ids)]\n",
    "\n",
    "min_max_dict = {}\n",
    "\n",
    "for row in relevant_ratings.itertuples(index=False):\n",
    "    movie_id = row.movie_id\n",
    "    rating = row.rating\n",
    "\n",
    "    if movie_id not in min_max_dict:\n",
    "        min_max_dict[movie_id] = {\"min\": rating, \"max\": rating}\n",
    "    else:\n",
    "        if rating < min_max_dict[movie_id][\"min\"]:\n",
    "            min_max_dict[movie_id][\"min\"] = rating\n",
    "        if rating > min_max_dict[movie_id][\"max\"]:\n",
    "            min_max_dict[movie_id][\"max\"] = rating\n",
    "\n",
    "# Updating\n",
    "for row in movie_stats.itertuples(index=True):\n",
    "    movie_id = row.movie_id\n",
    "\n",
    "    if movie_id in min_max_dict:\n",
    "        if pd.isna(row.min_rating):\n",
    "            movie_stats.at[row.Index, \"min_rating\"] = min_max_dict[movie_id][\"min\"]\n",
    "        if pd.isna(row.max_rating):\n",
    "            movie_stats.at[row.Index, \"max_rating\"] = min_max_dict[movie_id][\"max\"]\n",
    "\n",
    "dfs[\"movie_statistics\"] = movie_stats"
   ],
   "id": "b223c307fbaf3082"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculating missing mix and max ratings for films\n",
   "id": "d74f2d117c64282"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Merging the Movies and movie statis filling in missing values on either dataset and converting all of the dates to type DateTime.\n",
    "This is in order to clean our movie data before merging it with our user data."
   ],
   "id": "e72793c3ce2f365c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27ade6f930318473"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Converts the date parameter in viewer_ratings to datetime.\n",
    "- Merges viewer_ratings, movies, movie_statistics and user_statistics into one dataset as merged_data."
   ],
   "id": "6f7634f8be7ab453"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rating_data = pd.read_sql(\"SELECT * FROM viewer_ratings\", conn)\n",
    "movie_data = pd.read_sql(\"SELECT * FROM movies\", conn)\n",
    "user_data = pd.read_sql(\"SELECT * FROM user_statistics\", conn)\n",
    "movie_statistics = pd.read_sql(\"SELECT * FROM movie_statistics\", conn)\n",
    "\n",
    "rating_data['date'] = pd.to_datetime(rating_data['date'], errors = 'coerce')\n",
    "rating_data.dtypes\n",
    "movie_statistics['first_rating_date'] = \n",
    "\n",
    "merged_data = rating_data.merge(movie_data, on = 'movie_id', how = 'left')\n",
    "merged_data = merged_data.merge(user_data, on = 'customer_id', how = 'left')\n",
    "merged_data = merged_data.merge(movie_statistics, on = 'movie_id', how = 'left')\n",
    "# avg rating standard rating mean rating\n",
    "'''\n",
    "want to merge\n",
    "- title\n",
    "- year of release\n",
    "want to keep independent\n",
    "- avg rating\n",
    "- std rating\n",
    "- min rating\n",
    "- max rating\n",
    "- first rating date\n",
    "- last rating date\n",
    "'''\n",
    "\n",
    "print(\"Total columns:\", len(merged_data.columns))\n",
    "list(merged_data.columns)"
   ],
   "id": "a7ac6401a50adbad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f61839569a64fca8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a557034dea6eb542"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
